---
title: "Formatting and quality control of eDNA metabarcoding data (intertidal dataset)"
format: html
editor: visual
author: Dina-Leigh Simons
toc: true
---

## Load packages

```{r}
#| label: load-packages
#| echo: true
#| results: false
#| message: false
#| warning: false

list.of.packages <- c("dplyr", 
                      "tidyverse", 
                      "phyloseq", 
                      "seqinr", 
                      "dada2", 
                      "sjmisc", 
                      "worrms",
                      "taxize",
                      "tibble", 
                      "taxadb")

new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

invisible(lapply(list.of.packages, library, character.only = TRUE))
```

## Importing data

We'll first load all the required data, including outputs from the taxonomic assignment (.txt files), ASV data (.tsv and .fasta) and metadata (.csv).

### Taxonomic assignments

We BLASTed ASVs against curated databases (MIDORI2 for CO1, Silva for 18S) separately for five regions: Scotland, North and South Wales, Northeast England, and Southwest England.

The BLAST results were then processed using MEtaGenome ANalyzer (MEGAN), which parses the alignments and assigns taxonomy using the Lowest Common Ancestor (LCA) algorithm. This approach ensures accurate taxonomic classification by considering multiple hits while conservatively resolving ambiguous assignments.

```{r}
#| label: load-taxonomy-files
#| warning: false
#| echo: true

#Scotland----
SCH_18S_taxa<- read.table("Input_Data/MEGAN_data/SCH_18S_ASVs_blast_out_SILVA_98-ex.txt", header = F) #Scotland 18S
colnames(SCH_18S_taxa)<- c("ASV", "taxonomy")

SCH_CO1_taxa<- read.table("Input_Data/MEGAN_data/SCH_CO1_ASVs_blast_UNIQ_MIDORI_98-ex.txt", header = F) #Scotland CO1
colnames(SCH_CO1_taxa)<- c("ASV", "taxonomy")

#North wales----
NW_18S_taxa<- read.table("Input_Data/MEGAN_data/NW_18S_ASVs_blast_out_SILVA_98-ex.txt", header = F) #North Wales 18S
colnames(NW_18S_taxa)<- c("ASV", "taxonomy")

NW_CO1_taxa<- read.table("Input_Data/MEGAN_data/NW_CO1_ASVs_blast_UNIQ_MIDORI_98-ex_1per.txt", header = F) #North Wales CO1
colnames(NW_CO1_taxa)<- c("ASV", "taxonomy")

#South Wales----
SW_18S_taxa<- read.table("Input_Data/MEGAN_data/SW_18S_ASVs_blast_out_SILVA_98-ex.txt", header = F) #South Wales 18S
colnames(SW_18S_taxa)<- c("ASV", "taxonomy")

SW_CO1_taxa<- read.table("Input_Data/MEGAN_data/SW_CO1_ASVs_blast_UNIQ_MIDORI_98-ex.txt", header = F) #South Wales CO1
colnames(SW_CO1_taxa)<- c("ASV", "taxonomy")

#Northeast England----
NE_18S_taxa<- read.table("Input_Data/MEGAN_data/NE_18S_ASVs_blast_out_SILVA_98-ex.txt", header = F) #Northeast 18S
colnames(NE_18S_taxa)<- c("ASV", "taxonomy")

NE_CO1_taxa<- read.table("Input_Data/MEGAN_data/NE_CO1_ASVs_blast_UNIQ_MIDORI_98-ex.txt", header = F) #Northwast CO1
colnames(NE_CO1_taxa)<- c("ASV", "taxonomy")

#Southwest England (Cornwall)----
CN_18S_taxa<- read.table("Input_Data/MEGAN_data/CN_18S_ASVs_blast_out_SILVA-1per_98.txt", header = F) #Cornwall 18S
colnames(CN_18S_taxa)<- c("ASV", "taxonomy")

CN_CO1_taxa<- read.table("Input_Data/MEGAN_data/CN_CO1_ASVs_blast_UNIQ_MIDORI-1per_98.txt", header = F) #Cornwall CO1
colnames(CN_CO1_taxa)<- c("ASV", "taxonomy")

#Controls----
Controls_18S_taxa<- read.table("Input_Data/MEGAN_data/Controls_reps_18S_ASVs_blast_out_SILVA_98-ex.txt", header = F) #Controls 18S
colnames(Controls_18S_taxa)<- c("ASV", "taxonomy")

Controls_CO1_taxa<- read.table("Input_Data/MEGAN_data/Repeats_CO1_ASVs_blast_UNIQ_MIDORI_98-ex.txt", header = F) #Controls CO1
colnames(Controls_CO1_taxa)<- c("ASV", "taxonomy")
```

Let's take a look at one of the MEGAN outputs. This file shows the ASVs detected in Scotland derived from the CO1 gene.

```{r}
#| echo: true
#| label: head-taxa
head(SCH_CO1_taxa)
```

### ASV data

Now we import the ASV count and sequence information for each region, obtained using DADA2. We have to do a bit of wrangling to get the fasta file into the correct format.

```{r}
#| label: load-asv-files
#| warning: false
#| echo: true

#Scotland----
SCH_asv_count_18S <- read.table("Input_Data/HPC_processed_data/SCH_18S/06_ASV_counts_SCH_18S.tsv") #Scotland 18S counts
SCH_asv_fasta_18S <- read.fasta("Input_Data/HPC_processed_data/SCH_18S/06_ASV_seqs_SCH_18S.fasta")#Scotland 18S fasta
SCH_asv_fasta_18S_df <- data.frame(ASV=names(SCH_asv_fasta_18S), 
                                   Seqs=unlist(getSequence(SCH_asv_fasta_18S, as.string=T))) #turn into data frame
SCH_asv_fasta_18S_df$Seqs<- toupper(SCH_asv_fasta_18S_df$Seqs) #upper case Seqs

SCH_asv_count_CO1 <- read.table("Input_Data/HPC_processed_data/SCH_COI/06_ASV_counts_SCH_CO1_names.tsv") #Scotland CO1S counts
SCH_asv_fasta_CO1 <- read.fasta("Input_Data/HPC_processed_data/SCH_COI/06_ASV_seqs_SCH_CO1_names.fasta")#Scotland CO1 fasta
SCH_asv_fasta_CO1_df <- data.frame(ASV=names(SCH_asv_fasta_CO1), 
                                   Seqs=unlist(getSequence(SCH_asv_fasta_CO1, as.string=T))) #turn into data frame
SCH_asv_fasta_CO1_df$Seqs<- toupper(SCH_asv_fasta_CO1_df$Seqs) #upper case Seqs

#North Wales----
NW_asv_count_18S <- read.table("Input_Data/HPC_processed_data/NW_18S/06_ASV_counts.tsv") #North Wales 18S counts
NW_asv_fasta_18S <- read.fasta("Input_Data/HPC_processed_data/NW_18S/06_ASV_seqs.fasta")#North Wales 18S fasta
NW_asv_fasta_18S_df <- data.frame(ASV=names(NW_asv_fasta_18S), 
                                  Seqs=unlist(getSequence(NW_asv_fasta_18S, as.string=T))) #turn into data frame
NW_asv_fasta_18S_df$Seqs<- toupper(NW_asv_fasta_18S_df$Seqs) #upper case Seqs

NW_asv_count_CO1 <- read.table("Input_Data/HPC_processed_data/NW_CO1/06_ASV_counts.tsv") #North Wales CO1 counts
NW_asv_fasta_CO1 <- read.fasta("Input_Data/HPC_processed_data/NW_CO1/06_ASV_seqs.fasta")#North Wales CO1 fasta
NW_asv_fasta_CO1_df <- data.frame(ASV=names(NW_asv_fasta_CO1), 
                                  Seqs=unlist(getSequence(NW_asv_fasta_CO1, as.string=T))) #turn into data frame
NW_asv_fasta_CO1_df$Seqs<- toupper(NW_asv_fasta_CO1_df$Seqs) #upper case Seqs

#South Wales----
SW_asv_count_18S <- read.table("Input_Data/HPC_processed_data/SW_18S/06_ASV_counts_SW_18S.tsv") #South Wales 18S counts
SW_asv_fasta_18S <- read.fasta("Input_Data/HPC_processed_data/SW_18S/06_ASV_seqs_SW_18S.fasta") #South Wales 18S fasta
SW_asv_fasta_18S_df <- data.frame(ASV=names(SW_asv_fasta_18S), 
                                  Seqs=unlist(getSequence(SW_asv_fasta_18S, as.string=T))) #turn into data frame
SW_asv_fasta_18S_df$Seqs<- toupper(SW_asv_fasta_18S_df$Seqs) #upper case Seqs

SW_asv_count_CO1 <- read.table("Input_Data/HPC_processed_data/SW_CO1/06_ASV_counts_SW_CO1_names.tsv") #South Wales CO1 counts
SW_asv_fasta_CO1 <- read.fasta("Input_Data/HPC_processed_data/SW_CO1/06_ASV_seqs_SW_CO1_names.fasta") #South Wales CO1 fasta
SW_asv_fasta_CO1_df <- data.frame(ASV=names(SW_asv_fasta_CO1), 
                                  Seqs=unlist(getSequence(SW_asv_fasta_CO1, as.string=T))) #turn into data frame
SW_asv_fasta_CO1_df$Seqs<- toupper(SW_asv_fasta_CO1_df$Seqs) #upper case Seqs

#Northeast----
NE_asv_count_18S <- read.table("Input_Data/HPC_processed_data/NE_18S/06_ASV_counts_NE.tsv") #Northeast 18S counts
NE_asv_fasta_18S <- read.fasta("Input_Data/HPC_processed_data/NE_18S/06_ASV_seqs_NE.fasta")#Northeast 18S fasta
NE_asv_fasta_18S_df <- data.frame(ASV=names(NE_asv_fasta_18S), 
                                  Seqs=unlist(getSequence(NE_asv_fasta_18S, as.string=T))) #turn into data frame
NE_asv_fasta_18S_df$Seqs<- toupper(NE_asv_fasta_18S_df$Seqs) #upper case Seqs

NE_asv_count_CO1 <- read.table("Input_Data/HPC_processed_data/NE_CO1/06_ASV_counts.tsv") #Northeast CO1 counts
NE_asv_fasta_CO1 <- read.fasta("Input_Data/HPC_processed_data/NE_CO1/06_ASV_seqs.fasta")#Northeast CO1 fasta
NE_asv_fasta_CO1_df <- data.frame(ASV=names(NE_asv_fasta_CO1), 
                                  Seqs=unlist(getSequence(NE_asv_fasta_CO1, as.string=T))) #turn into data frame
NE_asv_fasta_CO1_df$Seqs<- toupper(NE_asv_fasta_CO1_df$Seqs) #upper case Seqs

#Cornwall----
CN_asv_count_18S <- read.table("Input_Data/HPC_processed_data/CN_18S/06_ASV_counts.tsv") #Cornwall 18S counts
CN_asv_fasta_18S <- read.fasta("Input_Data/HPC_processed_data/CN_18S/06_ASV_seqs.fasta")#Cornwall 18S fasta
CN_asv_fasta_18S_df <- data.frame(ASV=names(CN_asv_fasta_18S), 
                                  Seqs=unlist(getSequence(CN_asv_fasta_18S, as.string=T))) #turn into data frame
CN_asv_fasta_18S_df$Seqs<- toupper(CN_asv_fasta_18S_df$Seqs) #upper case Seqs

CN_asv_count_CO1 <- read.table("Input_Data/HPC_processed_data/CN_CO1/06_ASV_counts.tsv") #Cornwall CO1 counts
CN_asv_fasta_CO1 <- read.fasta("Input_Data/HPC_processed_data/CN_CO1/06_ASV_seqs.fasta")#Cornwall CO1 fasta
CN_asv_fasta_CO1_df <- data.frame(ASV=names(CN_asv_fasta_CO1), 
                                  Seqs=unlist(getSequence(CN_asv_fasta_CO1, as.string=T))) #turn into data frame
CN_asv_fasta_CO1_df$Seqs<- toupper(CN_asv_fasta_CO1_df$Seqs) #upper case Seqs

#Controls
controls_PhD2_asv_count_18S <- read.table("Input_Data/HPC_processed_data/Controls_18S/06_ASV_counts_Controls.tsv") #controls 18S counts
controls_PhD2_asv_fasta_18S <- read.fasta("Input_Data/HPC_processed_data/Controls_18S/06_ASV_seqs_Controls.fasta")#controls 18S fasta
controls_PhD2_asv_fasta_18S_df <- data.frame(ASV=names(controls_PhD2_asv_fasta_18S), 
                                             Seqs=unlist(getSequence(controls_PhD2_asv_fasta_18S, as.string=T))) #turn into data frame
controls_PhD2_asv_fasta_18S_df$Seqs<- toupper(controls_PhD2_asv_fasta_18S_df$Seqs) #upper case Seqs

controls_PhD2_asv_count_CO1 <- read.table("Input_Data/HPC_processed_data/Repeats_CO1/06_ASV_counts.tsv") #controls CO1 counts
controls_PhD2_asv_fasta_CO1 <- read.fasta("Input_Data/HPC_processed_data/Repeats_CO1/06_ASV_seqs.fasta")#controls  CO1 fasta
controls_PhD2_asv_fasta_CO1_df <- data.frame(ASV=names(controls_PhD2_asv_fasta_CO1), 
                                             Seqs=unlist(getSequence(controls_PhD2_asv_fasta_CO1, as.string=T))) #turn into data frame
controls_PhD2_asv_fasta_CO1_df$Seqs<- toupper(controls_PhD2_asv_fasta_CO1_df$Seqs) #upper case Seqs

```

Let's take a look at an example of the two imported ASV files. Again, these shows the ASVs detected in Scotland derived from the CO1 gene.

```{r}
#| echo: true
#| label: str-ASV
str(SCH_asv_count_CO1) #counts
```

```{r}
#| echo: true
#| label: head-ASV
head(SCH_asv_fasta_CO1_df) #sequences
```

### Metadata

Finally, let's import any metadata associated to our samples.

```{r}
#| label: load-metadata
sites <- read.csv("Input_Data/Metadata/eDNA_Site_Rockpool_Data_Oct2023.csv", na.strings=c("","NA"))
IDs_stageone <- read.csv("Input_Data/Metadata/sample_ID_matching_stageone.csv")
IDs_stagetwo <- read.csv("Input_Data/Metadata/sample_ID_matching_stagetwo.csv")
```

And let's take a quick look at the metadata files too. You can see there are 63 variables which are associated to our samples.

```{r}
#| label: str-meta
str(sites)
```

We also have some data to help tidy up sample IDs later in the pipeline.

```{r}
#| label: head-IDs
head(IDs_stageone) #labels
```

## Data wrangling to create a single data set

We have lots of different files here which need to be manipulated into one single data frame for each primer. A few steps are required to achieve this.

### Merge taxonomic assignments and ASV information

```{r}
#| label: merge-ASV-Seq

#Scotland----
SCH_asv_18S_merged <- merge(SCH_asv_fasta_18S_df, SCH_asv_count_18S, by.x = "Seqs", by.y = "row.names") #add ASVs to count data
SCH_taxa_18S <- full_join(SCH_18S_taxa, SCH_asv_18S_merged, by = "ASV") #full_join keeps ASVs which didn't get assigned, left_join would remove unassigned

SCH_asv_CO1_merged <- merge(SCH_asv_fasta_CO1_df, SCH_asv_count_CO1, by.x = "Seqs", by.y = "row.names") #add ASVs to count data
SCH_taxa_CO1 <- full_join(SCH_CO1_taxa, SCH_asv_CO1_merged, by = "ASV") #full_join keeps ASVs which didn't get assigned, left_join would remove unassigned

#North Wales----
NW_asv_18S_merged <- merge(NW_asv_fasta_18S_df, NW_asv_count_18S, by.x = "Seqs", by.y = "row.names") #add ASVs to count data
NW_taxa_18S <- full_join(NW_18S_taxa, NW_asv_18S_merged, by = "ASV") #full_join keeps ASVs which didn't get assigned, left_join would remove unassigned

NW_asv_CO1_merged <- merge(NW_asv_fasta_CO1_df, NW_asv_count_CO1, by.x = "Seqs", by.y = "row.names") #add ASVs to count data
NW_taxa_CO1 <- full_join(NW_CO1_taxa, NW_asv_CO1_merged, by = "ASV") #full_join keeps ASVs which didn't get assigned, left_join would remove unassigned

#South Wales----
SW_asv_18S_merged <- merge(SW_asv_fasta_18S_df, SW_asv_count_18S, by.x = "Seqs", by.y = "row.names") #add ASVs to count data
SW_taxa_18S <- full_join(SW_18S_taxa, SW_asv_18S_merged, by = "ASV") #full_join keeps ASVs which didn't get assigned, left_join would remove unassigned

SW_asv_CO1_merged <- merge(SW_asv_fasta_CO1_df, SW_asv_count_CO1, by.x = "Seqs", by.y = "row.names") #add ASVs to count data
SW_taxa_CO1 <- full_join(SW_CO1_taxa, SW_asv_CO1_merged, by = "ASV") #full_join keeps ASVs which didn't get assigned, left_join would remove unassigned

#Northeast----
NE_asv_18S_merged <- merge(NE_asv_fasta_18S_df, NE_asv_count_18S, by.x = "Seqs", by.y = "row.names") #add ASVs to count data
NE_taxa_18S <- full_join(NE_18S_taxa, NE_asv_18S_merged, by = "ASV") #full_join keeps ASVs which didn't get assigned, left_join would remove unassigned

NE_asv_CO1_merged <- merge(NE_asv_fasta_CO1_df, NE_asv_count_CO1, by.x = "Seqs", by.y = "row.names") #add ASVs to count data
NE_taxa_CO1 <- full_join(NE_CO1_taxa, NE_asv_CO1_merged, by = "ASV") #full_join keeps ASVs which didn't get assigned, left_join would remove unassigned

#Cornwall----
CN_asv_18S_merged <- merge(CN_asv_fasta_18S_df, CN_asv_count_18S, by.x = "Seqs", by.y = "row.names") #add ASVs to count data
CN_taxa_18S <- full_join(CN_18S_taxa, CN_asv_18S_merged, by = "ASV") #full_join keeps ASVs which didn't get assigned, left_join would remove unassigned

CN_asv_CO1_merged <- merge(CN_asv_fasta_CO1_df, CN_asv_count_CO1, by.x = "Seqs", by.y = "row.names") #add ASVs to count data
CN_taxa_CO1 <- full_join(CN_CO1_taxa, CN_asv_CO1_merged, by = "ASV") #full_join keeps ASVs which didn't get assigned, left_join would remove unassigned

#Controls----
Controls_asv_18S_merged <- merge(controls_PhD2_asv_fasta_18S_df, controls_PhD2_asv_count_18S, by.x = "Seqs", by.y = "row.names") #add ASVs to count data
Controls_taxa_18S <- full_join(Controls_18S_taxa, Controls_asv_18S_merged, by = "ASV") #full_join keeps ASVs which didn't get assigned, left_join would remove unassigned

Controls_asv_CO1_merged <- merge(controls_PhD2_asv_fasta_CO1_df, controls_PhD2_asv_count_CO1, by.x = "Seqs", by.y = "row.names") #add ASVs to count data
Controls_taxa_CO1 <- full_join(Controls_CO1_taxa, Controls_asv_CO1_merged, by = "ASV") #full_join keeps ASVs which didn't get assigned, left_join would remove unassigned
```

### Remove undetermined sequences in 18S data

Sequences that were unable to be assigned to a specific sample in the 18S are stored under the variable 'S0'. We want to remove those sequences from our data.

```{r}
#| label: remove-undetermined-seqs

drop <- c("S0") # set which variable we want to remove (undetermined in MiniSeq run)

SCH_taxa_18S <- SCH_taxa_18S[,!(names(SCH_taxa_18S) %in% drop)]
NW_taxa_18S <- NW_taxa_18S[,!(names(NW_taxa_18S) %in% drop)]
SW_taxa_18S <- SW_taxa_18S[,!(names(SW_taxa_18S) %in% drop)] 
NE_taxa_18S <- NE_taxa_18S[,!(names(NE_taxa_18S) %in% drop)]
CN_taxa_18S <- CN_taxa_18S[,!(names(CN_taxa_18S) %in% drop)]
Controls_taxa_18S <- Controls_taxa_18S[,!(names(Controls_taxa_18S) %in% drop)]

```

### Convert to long format

Here, we flip the data sets into a long format and add a region variable.

```{r}
#| label: convert-long

#Scotland----
flip_SCH_18S <- gather(SCH_taxa_18S, sample, reads, S66:S132) 
flip_SCH_18S$region <- "Scotland"

flip_SCH_CO1 <- gather(SCH_taxa_CO1, sample, reads, Adapter3616.SCH01.04rep:Adapter453.SCHNC2803) #this is not number order, this is first and last column
flip_SCH_CO1$region <- "Scotland"

#North Wales----
flip_NW_18S <- gather(NW_taxa_18S, sample, reads, S1:S51) 
flip_NW_18S$region <- "North Wales"

flip_NW_CO1 <- gather(NW_taxa_CO1, sample, reads, X1.NW01.01:X9.NW02.06) #this is not number order, this is first and last column
flip_NW_CO1$region <- "North Wales"

#South Wales----
flip_SW_18S <- gather(SW_taxa_18S, sample, reads, S60:S54) 
flip_SW_18S$region <- "South Wales"

flip_SW_CO1 <- gather(SW_taxa_CO1, sample, reads, Adapter3553.SW01.01:Adapter3620.PCrep) #this is not number order, this is first and last column
flip_SW_CO1$region <- "South Wales"

#Northeast----
flip_NE_18S <- gather(NE_taxa_18S, sample, reads, S73:S123) 
flip_NE_18S$region <- "Northeast England"

flip_NE_CO1 <- gather(NE_taxa_CO1, sample, reads, X100.NE05.02:X99.NE05.01) #this is not number order, this is first and last column
flip_NE_CO1$region <- "Northeast England"

#Cornwall----
flip_CN_18S <- gather(CN_taxa_18S, sample, reads, S133:S183) 
flip_CN_18S$region <- "Cornwall"

flip_CN_CO1 <- gather(CN_taxa_CO1, sample, reads, X115.CN01.01:X192.CN01.02rep) #this is not number order, this is first and last column
flip_CN_CO1$region <- "Cornwall"

#Controls----
flip_controls_18S <- gather(Controls_taxa_18S, sample, reads, S34:S61) #this is not number order, this is first and last column
flip_controls_18S$region <- "Varied"

flip_controls_CO1 <- gather(Controls_taxa_CO1, sample, reads, X173.SCH02.03:X195.minusVEpcr) #this is not number order, this is first and last column
flip_controls_CO1$region <- "Varied"

```

Let's take a look at the long format for Scotland CO1. We now have a long format data set with ASVs, taxonomy, sequences, sample names, number of reads and region variables.

```{r}
#| label: head-flipped
head(flip_SCH_CO1)
```

### Join data frames

We will merge our data in multiple stages: first by sequencing run, then by gene, and finally, we will perform the final join. Once we have our single data frame, we'll add in our metadata.

Our data was derived from multiple sequences runs. Therefore, we are going to join the data in the same sequencing run first. This means we can correctly match IDs we want to sample names.

```{r}
#| label: join-seq-run

# Merge stage-one locations (SCH and SW) and add IDs
full_stageone_18S <-rbind(flip_SCH_18S, flip_SW_18S) %>% 
  dplyr::rename(sample_18S = sample) %>% #rename sample column to match
  full_join(IDs_stageone, by = "sample_18S")

full_stageone_18S$region <- as.factor(full_stageone_18S$region)

full_stageone_CO1 <-rbind(flip_SCH_CO1, flip_SW_CO1) %>% 
  dplyr::rename(sample_CO1 = sample) %>% #rename sample column to match
  full_join(IDs_stageone, by = "sample_CO1")

full_stageone_CO1$region <- as.factor(full_stageone_CO1$region)

# Merge stage-two locations (controls, CN, NE, NW)
full_stagetwo_18S <-rbind(flip_controls_18S, flip_CN_18S, flip_NE_18S, flip_NW_18S) %>% 
  dplyr::rename(sample_18S = sample) %>% 
  left_join(IDs_stagetwo, by = "sample_18S")

full_stagetwo_18S$region <- as.factor(full_stagetwo_18S$region)

full_stagetwo_CO1 <-rbind(flip_controls_CO1, flip_CN_CO1, flip_NE_CO1, flip_NW_CO1) %>%
  dplyr::rename(sample_CO1 = sample) %>% 
  full_join(IDs_stagetwo, by = "sample_CO1")

full_stagetwo_CO1$region <- as.factor(full_stagetwo_CO1$region)
```

Now we join data sets by primer and add primer variable. This will leave us with two main data sets, one for 18S and one for CO1. We also want to make sure out wrangling worked as expected by checking there are no duplicate rows.

```{r}
#| label: join-primer

full_18S <- rbind(full_stageone_18S, full_stagetwo_18S) #18s
full_18S$primer <- "18S"
any(duplicated(full_18S)) #check for duplicates - should be false

full_CO1 <- rbind(full_stageone_CO1, full_stagetwo_CO1) #CO1
full_CO1$primer <- "CO1"
any(duplicated(full_CO1)) #check for duplicates - should be false
```

Finally, we join the two primer data sets into a single data set.

```{r}
#| label: join-final

eDNA_ASVs_long <- rbind(full_18S, full_CO1)
any(duplicated(eDNA_ASVs_long)) #check for duplicates - should be false (this may take a minute or so)
```

Let's now add in our metadata and do some final tweaks to sample names.

```{r}
#| label: add-metadata

eDNA_long_data <- eDNA_ASVs_long %>% 
  subset(select = -c(sample_18S, sample_CO1)) %>% 
  dplyr::rename(fieldID = sample_ID)
eDNA_long_data <- full_join(eDNA_long_data, sites, by = "fieldID")

eDNA_long_data$fullID = paste(eDNA_long_data$fieldID, eDNA_long_data$primer, sep="_") #adds CO1 or 18S onto the end of the fieldID for further analyses
```

Great - we now have a single long data set with all ASV across samples and genes, as well as associated metadata.

```{r}
#| label: str-long-data

str(eDNA_long_data)
```

## Cleaning taxonomic names

Now we have our data, we need to tidy up our taxonomic names and get more information on the taxa we've detected.

### Remove ambiguous names

We first remove any occurrences where the taxonomic matches certain ambiguous phrases. These assignment tell us nothing about the organism we've detected, so it's best to remove them.

```{r}
#| label: remove-ambiguous-names

unassigned_phrases <- c("uncultured", "Uncultured", "unclassified", "Unclassified", "NCBI", 
             "pseudo", "Pseudo", "Not assigned", "not assigned", "SAR", "sar", 
             "cellular", "Cellular", "environmental", "Environemental", 
             "eukaryote", "Eukaryote", "eukaryota", "Eukaryota")

eDNA_long_data_cleaning <- eDNA_long_data[!grepl(paste(unassigned_phrases, collapse = "|"), eDNA_long_data$taxonomy),] %>%
  drop_na(taxonomy)

```

### Using clean_names() in janitor package

We often get random spaces or phrases we don't want in our taxonomic names. We can use the [janitor package](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html) to clean our taxonomic names.

```{r}
#| message: false
#| label: clean-names-janitor

names <- unique(eDNA_long_data_cleaning$taxonomy) #get all unique names from the data
cleaned_names <- clean_names(names) #clean names using janitor package in tidyverse
names_together <- data.frame(names, cleaned_names) %>% 
  dplyr::rename(taxonomy = names, taxonomy_clean = cleaned_names) %>% #join cleaned names next to original
  mutate(taxonomy_clean = gsub(' cf','', taxonomy_clean)) %>% #remove cfs which function didn't remove
  mutate(taxonomy_clean = gsub('cf ','', taxonomy_clean)) #remove cfs which function didn't remove

eDNA_long_data_cleaned <- full_join(names_together, eDNA_long_data_cleaning)

```

We should now have a variable added to our data set called taxonomy_clean. We will use this variable as the taxonomic name moving forward.

```{r}
#| label: str-long-data-clean

str(eDNA_long_data_cleaned)
```

We can see the data set is a lot smaller after removal of rows with ambiguous names.

## Extracting information from WoRMS

The [World Register of Marine Species](https://www.marinespecies.org/) (WoRMS) is an authoritative classification and catalogue of marine names. It can provide a range of information. We will be extracting information on taxonomy and functional trait information using the taxize and worrms functions.

### Defining functions

First, we've got to set-up some functions.

The first function called `get_wormsid_noerror` extracts unique identifiers for all taxon used in WoRMS called AphiaIDs.

```{r}
#| label: define-function-wormsid

get_wormsid_noerror <- function(sp_name){
  wm_id <- try(taxize::get_wormsid(sp_name,
                                   accepted = TRUE, 
                                   searchtype= "scientific", 
                                   marine_only = FALSE,
                                   ask = FALSE,
                                   row = 1,
                                   message = FALSE),
               silent = TRUE)
  
  #remove end word to attempt matching genus when previous no match
  
  if(class(wm_id) == "try-error"){
    sp_name <- str_remove(sp_name, "(\\s+\\w+)") 
    wm_id <- try(taxize::get_wormsid(sp_name,
                                     accepted = TRUE, 
                                     searchtype= "scientific", 
                                     marine_only = FALSE,
                                     ask = FALSE,
                                     row = 1,
                                     message = FALSE),
                 silent = TRUE)
  } 
  
  #convert non-matched species to NA AphiaID
  
  if(class(wm_id) == "try-error"){
    wm_id <- NA
  } 
  tibble(sciname = sp_name, aphiaID = as.double(unlist(wm_id)))
}
```

The second function called `get_wormsmeta` accesses and formats any taxonomic meta data based on Aphia IDs.

```{r}
#| label: define-function-wormsmeta

get_wormsmeta <- function(aphia_input){
  
  #split into smaller chunks for wm_record() to work
  taxadf_split <- split(aphia_input, (seq(nrow(aphia_input))-1) %/% 50) #split into smaller groups for worms to work
  temp_df <- data.frame()
  
  #run wm_record() through split list
  for (i in taxadf_split) {
    taxa_temp <- wm_record(id = i$aphiaID)
    temp_df = rbind(temp_df, taxa_temp)
  }
  tibble(temp_df)
}
```

The third function called `get_worms_fgrp` (originally developed [here](https://github.com/tomjwebb/WoRMS-functional-groups)) accesses and formats information on broad taxonomic groupings of taxa based on Aphia IDs.

```{r}
#| label: define-function-worms-fgrp

get_worms_fgrp <- function(AphiaID) {
  
  #' First, test if the species has attribute data
  attr_dat <- try(wm_attr_data(
    AphiaID, include_inherited = TRUE), silent = TRUE)
  
  #' set up out as null for later use
  out <- NULL
  
  if(!identical(class(attr_dat), "try-error")){
    
    #' if attribute data exists, test if functional group is there
    if("Functional group" %in% attr_dat$measurementType){
      fg_dat <- attr_dat %>% filter(measurementType == "Functional group")
      
      #' Insert if statement here about $children empty
      #' assign the $children - so that it can be used 
      children <- fg_dat$children
      
      if(max(lengths(children)) > 0 ){
        #' Extract the life stage information from the $children field
        life_stage <- children %>% bind_rows() %>%
          dplyr::select(measurementValue) %>%
          dplyr::rename(stage = measurementValue)
        
        #' add in rows for instances missing children
        idx <- which(lengths(children) == 0)
        if(length(idx) > 0){
          life_stage_null <- tibble(stage = rep(as.character(NA), length(children)))
          idy <- (1:length(children))[-idx]
          life_stage_null[idy,] <- life_stage
          life_stage <- life_stage_null
        }
        life_stage <- life_stage %>% bind_cols(., fg_dat)
        
        #' deal with cases where multiple records are returned for the same life stage:
        #' add a suffix to subsequent identical stages (adult_2, etc.)        
        life_stage <- life_stage %>% group_by(stage) %>% dplyr::mutate(nth_stage_val = 1:n()) %>% 
          ungroup() %>% 
          mutate(stage = case_when(
            nth_stage_val == 1 ~ stage,
            TRUE ~ paste(stage, nth_stage_val, sep = "_")
          )
          ) %>% 
          select(-nth_stage_val)
        
        #' create the output to return
        out <- tibble(AphiaID = as.numeric(life_stage$AphiaID),
                      stage = life_stage$stage, fun_grp = life_stage$measurementValue)
        
      } else{
        #' If no life stage info, assume stage is adult
        out <- tibble(AphiaID = as.numeric(fg_dat$AphiaID),
                      stage = "adult", fun_grp = fg_dat$measurementValue)
        
        #' Deal with cases where multiple records are returned (i.e. 2 or more adult fun_grps)
        if(nrow(out) > 1){
          out <- out %>% group_by(stage) %>% dplyr::mutate(nth_stage_val = 1:n()) %>% 
            ungroup() %>% 
            mutate(stage = case_when(
              nth_stage_val == 1 ~ stage,
              TRUE ~ paste(stage, nth_stage_val, sep = "_")
            )
            ) %>% 
            select(-nth_stage_val)
        }
      } 
    }
    
    #' add Pisces, from paraphyletic group: this takes priority over the above
    #' (e.g. class something as Pisces if it is a fish even if it is also listed as benthos)
    if ("Paraphyletic group" %in% attr_dat$measurementType) {
      if(first(
        attr_dat$measurementValue[attr_dat$measurementType == "Paraphyletic group"] == "Pisces")){
        out <- tibble(AphiaID = AphiaID, stage = "adult",
                      fun_grp = first(attr_dat$measurementValue[
                        attr_dat$measurementType == "Paraphyletic group"]))
      }
    }
  }
  #' add other paraphyletic groups: Algae, Algae > Macroalgae, Mangroves this DOES NOT takes priority over the above; i.e. only use if a functional group (e.g. phytoplankton) is not available
  if(is.null(out)){
    if (!identical(class(attr_dat), "try-error") && "Paraphyletic group" %in% attr_dat$measurementType) {
      out <- tibble(AphiaID = AphiaID, stage = "adult",
                    fun_grp = first(attr_dat$measurementValue[
                      attr_dat$measurementType == "Paraphyletic group"]))
    }
  }
  
  #' check taxonomy for other groups
  if(is.null(out)){
    taxo_dat <- try(wm_classification(AphiaID), silent = TRUE)
    if(identical(class(taxo_dat), "try-error")){
      fg <- as.character(NA)
    } else {
      fg <- case_when(
        "Aves" %in% taxo_dat$scientificname ~ "birds",
        "Mammalia" %in% taxo_dat$scientificname ~ "mammals",
        "Reptilia" %in% taxo_dat$scientificname ~ "reptiles",
        TRUE ~ as.character(NA)
      )
    }
    out <- tibble(AphiaID = AphiaID, stage = "adult", fun_grp = fg)
  }
  
  #' what if there are duplicate rows?
  out <- out[!duplicated(out), ]
  out <- out[!(is.na(out$stage)),] #gets rid of NA stages
  
  #' Replace 'not applicable' with NA
  out <- out %>% mutate_all(~ifelse(. == 'not applicable', NA, .))
  
  #' Keep only the life stage with the highest number (if applicable)
  out <- out %>%
    separate(stage, into = c("stage", "number"), sep = "_", remove = FALSE) %>%
    group_by(AphiaID, stage) %>%
    arrange(desc(number)) %>%
    slice(1) %>%
    ungroup() %>%
    select(-number)
  
  #' Convert specific life stages to 'larva_other'
  out <- out %>% mutate(stage = case_when(
    stage %in% c('cerinula', 'larva > planula', 'medusa', 'zoea', 'nauplius', 'polyp', 'medusoid', 'ephyra', 'colony') ~ 'larva_other',
    TRUE ~ stage
  ))
  
  #' do some tidying of the output: tidy up functional_group text
  #' and spread to give one column per life stage
  out <- out %>% 
    distinct(AphiaID, stage, .keep_all = TRUE) %>%  # Add this line to remove duplicates
    mutate(functional_group = case_when(
      str_detect(fun_grp, ">") ~ tolower(word(fun_grp, -1)),
      fun_grp == "Pisces" ~ "fish",
      fun_grp == "Algae > Macroalgae" ~ "macroalgae",
      TRUE ~ tolower(fun_grp)
    )) %>%
    dplyr::select(-fun_grp) %>%
    spread(stage, functional_group)
  
  #' Change column name NA to other
  colnames(out)[colnames(out) == "NA"] <- "other"
  
  #' output the fg data
  out
}
```

Before we run anything, we need to extract the taxa names we want to run through the functions.

```{r}
#| label: get-taxa-names

eDNA_taxa_unique_list <- unique(eDNA_long_data_cleaned$taxonomy_clean) #Get unique taxa for WoRMs input as list
eDNA_taxa_unique_df <- data.frame(taxonomy = tolower(unique(eDNA_long_data_cleaned$taxonomy_clean)), 
                                  stringsAsFactors = FALSE) ##Get unique taxa for WoRMs input as df

head(eDNA_taxa_unique_df)
```

### Get Aphia IDs

Let's use the function `get_wormsid()` to obtain Aphia IDs for our taxa.

The duration of this task is approximately 15-minutes for this data set, but can vary depending on the size of the data. Any non-matched species will produce a NA.

To prevent the document taking hours to render, we've put \# in front of the code for now. We've saved the output and reloaded the data back in.

```{r}
#| label: get-worms-alphia

#aphiaID_worms_output <- eDNA_taxa_unique_list %>%
  #purrr::map(get_wormsid_noerror, .progress = TRUE) %>%
  #enframe() %>%
  #unnest(cols = everything()) %>%
  #select(-name)
```

We'll save this output to reduce time when rerunning.

```{r}
#| label: write-worms-alphia

#write.csv(aphiaID_worms_output, "Processed_Data/aphiaID_worms_output.csv")
```

Let's reload the data back in and do some formatting.

```{r}
#| label: reload--worms-alphia

aphiaID_worms_output <- read.csv("Processed_Data/aphiaID_worms_output.csv", row.names = 1)

aphiaID_worms_output$taxonomy_clean = eDNA_taxa_unique_df$taxonomy #add previous taxonomy name for joining later (order remains the same)
aphiaID_worms_output$aphiaID = as.integer(aphiaID_worms_output$aphiaID) #convert to integer for joining

head(aphiaID_worms_output)
```

Let's check how many matches we made.

```{r}
#| echo: false
#| label: match-worms-alphia
#| 
print(paste("You matched", nrow(eDNA_taxa_unique_df) - sum(is.na(aphiaID_worms_output$aphiaID)),"/", nrow(eDNA_taxa_unique_df), "taxa with AphiaIDs. Therefore,", sum(is.na(aphiaID_worms_output$aphiaID)), "entries could not be matched and do not have AphiaIDs."))
```

Now let's add the Aphia IDs to our main data set.

```{r}
#| label: join-worms-alphia

eDNA_long_data_final <- full_join(eDNA_long_data_cleaned, aphiaID_worms_output, by = join_by(taxonomy_clean))

str(eDNA_long_data_final)
```

### Get taxonomic metadata

Next, let's use the function `get_wormsmeta()` to obtain taxonomic information for our Aphia IDs. This command takes a few minutes to run.

```{r}
#| label: get-worms-meta

worms_meta_output <- get_wormsmeta(aphiaID_worms_output)
```

Let's look at the output. We can see we now have lots of information for each taxon.

```{r}
#| label: view-worms-meta

str(worms_meta_output)
```

A bit of tidying of this output is required to be able to join it with our own.

```{r}
#| label: tidy-worms-meta

worms_meta_output_tidy <- worms_meta_output %>%
  dplyr::rename(aphiaID = AphiaID) %>%
  filter(!is.na(aphiaID)) %>% #remove NAs
  distinct() #remove duplicates
```

Now let's add the taxonomic metadata to our main data set and check the joining of data sets worked.

```{r}
#| label: join-worms-meta

eDNA_long_data_final <- right_join(eDNA_long_data_final, worms_meta_output_tidy, by = "aphiaID") #worms meta

which(is.na(eDNA_long_data_final$aphiaID), arr.ind=TRUE) #check NAs in IDs
any(duplicated(eDNA_long_data_final)) #check for duplicates
```

### Get broad functional groups

Finally, let’s use the function `get_worms_fgrp()` to obtain the broad taxonomic groups of our taxa.

Similar to above, this command takes a long time (approximately 30 minutes with this data set). We have put \# in front of this code to reduce time to render.

```{r}
#| label: get-worms-fgrp

species <- tibble(AphiaID = c(unique(eDNA_long_data_final$aphiaID))) #list aphiaIDs

#worms_fgrp_output <- species %>%
  #group_by(AphiaID) %>%
  #do(get_worms_fgrp(AphiaID = .$AphiaID))
```

We'll save this output to reduce time when rerunning.

```{r}
#| label: write-worms-fgrp  

#write.csv(worms_fgrp_output, "Processed_Data/worms_fgrp_output.csv")
```

Let's reload the data back in.

```{r}
#| label: reload-worms-fgrp  

worms_fgrp_output <- read.csv("Processed_Data/worms_fgrp_output.csv", row.names = 1)
```

Let's see how many matches we got.

```{r}
#| label: match_worms-fgrp 
#| echo: false 

print(paste("You found function groups for", nrow(worms_fgrp_output) - sum(is.na(worms_fgrp_output$adult)),"/", nrow(worms_fgrp_output), "adult taxa. Therefore,", sum(is.na(worms_fgrp_output$adult)), "have no functional group."))
```

Now let's add the functional group information to our main data set and check the joining of data sets worked.

```{r}
#| label: join-worms-fgrp
#| message: false

worms_fgrp_output_tidy<- worms_fgrp_output %>% dplyr::rename(aphiaID = AphiaID)
eDNA_long_data_final <- left_join(eDNA_long_data_final, worms_fgrp_output_tidy)
```

Quick look at the final long data set (remember this has not been decontaminated yet!).

```{r}
#| label: str-long-data-final

str(eDNA_long_data_final)
```

## Create phyloseq object

We've now got a tidied long data set with lots of meta data. To aid further check and analyses, we can convert our long data into a phyloseq object.

First, we need to document and remove any failed samples.

```{r}
#| label: remove-failed-samples  

failed_samples <- c("PHD1-SCH02-03_CO1",
                    "PHD1-SCH02-05_CO1",
                    "PHD1-SCH03-05rep_CO1",
                    "PHD1-SCH04-03_CO1",
                    "PHD1-SCH06-05_18S",
                    "PHD1-SW04-01_CO1",
                    "PHD1-SW06-02_18S",
                    "PHD2-CN02-03_18S",
                    "PHD2-CN05-02_18S",
                    "PHD2-NE01-09_CO1",
                    "PHD2-NE02-03_CO1",
                    "PHD2-NE04-03_18S",
                    "PHD2-NW03-01_CO1")

eDNA_long_data_removefailed <- filter(eDNA_long_data_final, !fullID %in% failed_samples)
```

### Create tax_table()

We need to extract all the taxonomic information from our long data and do some tidying.

```{r}
#| label: format-tax-table  

taxa <- unique(subset(eDNA_long_data_removefailed, select = c("kingdom", 
                                             "phylum", 
                                             "class", 
                                             "order", 
                                             "family", 
                                             "genus", 
                                             "valid_name",
                                             "adult", #adult is functional group
                                             "valid_AphiaID",
                                             "rank"))) 

taxa$valid_name <- as.factor(taxa$valid_name)
taxa <- taxa[order(taxa$valid_name),] #order alphabetically to match other ps elements
rownames(taxa) <-taxa$valid_name
taxa <- as.matrix(taxa)
```

Now, save the taxa matrix as a tax_table() object.

```{r}
#| label: create-tax-table   

phylo_tax <- tax_table(taxa)
```

### Create sample_data()

Similarly, need to extract all the relavent sample information from our long data and do some tidying.

```{r}
#| label: format-sample-table

meta <- unique(subset(eDNA_long_data_removefailed, select = c("fieldID",
                                             "projectID",
                                             "eventID",
                                             "type", 
                                             "verbatimLocality",
                                             "localityID",
                                             "shorePosition", 
                                             "fullID",
                                             "year",
                                             "month",
                                             "day",
                                             "eventTime",
                                             "dna_concentration_CO1",
                                             "dna_concentration_18S",
                                             "negCheckLogical",
                                             "pairedRepLogical",
                                             "country",
                                             "controlCheck",
                                             "sampleType",
                                             "primer",
                                             "date_amplified_CO1",
                                             "date_amplified_18S",
                                             "batch_extraction",
                                             "batch_PCR_CO1",
                                             "plate_col_CO1",
                                             "plate_row_CO1",
                                             "batch_PCR_18S",
                                             "plate_col_18S",
                                             "plate_row_18S",
                                             "date_extraction",
                                             "exposure",
                                             "weather",
                                             "tide",
                                             "lowWater",
                                             "decimalLongitude",
                                             "decimalLatitude",
                                             "eventTime",
                                             "rockpoolarea.cm.2.",
                                             "averageDepth..cm.",
                                             "rockpoolVol.m.3.",
                                             "averagePH",
                                             "averageTemp"
)))

meta <- meta[order(meta$fullID),] #order alphabetically to match objects later
rownames(meta) <-meta$fullID
```

Now, save the sample matrix as a sample_data() object.

```{r}
#| label: create-sample-table

phylo_samples <- sample_data(meta)
```

### Create otu_table()

Since we are currently in long format, we need to recreate the ASV matrix with some data wrangling.

```{r}
#| label: format-otu-table

species_reads_long <- eDNA_long_data_removefailed %>%
  select(valid_name, reads, fullID) %>%
  mutate(across(c(valid_name, fullID), as.factor)) %>%
  distinct()

head(species_reads_long)
```

```{r}

species_reads_wide <- species_reads_long %>% spread(fullID, reads, fill = 0)
species_reads_wide<- species_reads_wide[order(species_reads_wide$valid_name),] #order alphabetically to match objects later
species_reads_wide <- species_reads_wide %>% column_to_rownames(var="valid_name")
```
